# LLM Orchestration via Cortical Messaging Protocol

A formally verified multi-LLM coordination system that treats language models as distributed agents with mathematical guarantees.

## ğŸ§  What This Is

This system implements **Cortical Messaging Protocol (CMP)** adapted for LLM coordination. Instead of coordinating robots in physical space, we coordinate language models in "semantic space" with:

- **Semantic Poses**: Position in concept space + confidence orientation
- **Evidence Aggregation**: Bayesian confidence combination across agents
- **Formal Verification**: Mathematical guarantees (Safety, Liveness, Consistency, Completeness)
- **Specialized Agents**: 7 expert LLMs working in parallel
- **External Data Integration**: Live manufacturing data via MTConnect MCP integration
- **Orchestration Engine**: Multi-agent coordination with consensus building

## ğŸ¯ Current Status: Phase 4 Complete âœ…

**Core CMP Infrastructure (Phase 1):**
- âœ… Semantic pose operations in concept space
- âœ… Agent message creation and processing  
- âœ… Evidence aggregation with confidence tracking
- âœ… Cross-agent compatibility checking
- âœ… Configurable model management

**Model Interface Layer (Phase 2):**
- âœ… Real OpenAI/Anthropic API integration
- âœ… CMP-to-LLM protocol translation
- âœ… Specialized prompt templates per agent type
- âœ… Response parsing from LLM to CMP format
- âœ… Model adapter factory system

**Agent Specialization System (Phase 3):**
- âœ… 7 distinct specialized agent types (Reasoning, Creative, Factual, Code, Social, Critic, Coordinator)
- âœ… Agent-specific reasoning morphology extraction
- âœ… Knowledge domain transformation system (14 transformation matrices)
- âœ… Cross-domain compatibility checking and confidence adjustments
- âœ… Specialized analysis approaches per agent expertise

**Orchestration Engine (Phase 4):**
- âœ… Multi-agent coordination with parallel execution
- âœ… Consensus building algorithms with formal verification
- âœ… Real-time evidence aggregation and conflict resolution
- âœ… MCP integration for external data sources (MTConnect manufacturing data)
- âœ… Enhanced orchestration requests with external context support

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
npm install
```

### 2. Configure API Keys
Choose the appropriate configuration for your setup:

**For OpenAI + Anthropic (recommended):**
```bash
cp config.anthropic_openai.example.json config.json
# Edit config.json with your OpenAI and Anthropic API keys
```

**For OpenAI + Anthropic + Google Gemini:**
```bash
cp config.anthropic_openai_google.example.json config.json
# Edit config.json with your OpenAI, Anthropic, and Google API keys
```

**For LM Studio (local models):**
```bash
cp config.lmstudio.example.json config.json
# Ensure LM Studio is running locally
```

**For Testing (no API keys required):**
```bash
cp config.mock.example.json config.json
# Uses mock responses for development
```

### 3. Run Demonstrations

**Core Phase 4 Orchestration Demo:**
```bash
npm run dev
```

**MCP Integration Demo (Manufacturing Data Analysis):**
```bash
npm run demo:mcp-integration
```

**Debug MCP Integration:**
```bash
npm run debug:mcp-integration
# Or use the included debug scripts:
# ./debug-mcp.sh (Linux/Mac)
# debug-mcp.bat (Windows)
```

**Note**: Phase 1 demo runs without API keys, but Phase 2+ require real API access for LLM integration. MCP integration requires MTConnect MCP server setup.

## ğŸ“ Project Structure

```
llm-cmp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ types/index.ts              # Core type definitions
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ semantic-pose.ts        # Semantic space operations
â”‚   â”‚   â”œâ”€â”€ llm-agent.ts            # Agent base class with specialization
â”‚   â”‚   â”œâ”€â”€ knowledge-domains.ts    # Cross-domain transformations
â”‚   â”‚   â””â”€â”€ ...                     # Core CMP functionality
â”‚   â”œâ”€â”€ orchestration/              # NEW: Orchestration Engine
â”‚   â”‚   â”œâ”€â”€ llm-orchestrator.ts     # Multi-agent coordination engine
â”‚   â”‚   â”œâ”€â”€ enhanced-request.ts     # Enhanced orchestration requests
â”‚   â”‚   â””â”€â”€ index.ts                # Orchestration exports
â”‚   â”œâ”€â”€ mcp/                        # NEW: Model Context Protocol Integration
â”‚   â”‚   â””â”€â”€ mcp-client.ts           # MTConnect MCP client
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model-adapter.ts        # Abstract base for API adapters
â”‚   â”‚   â”œâ”€â”€ openai-adapter.ts       # OpenAI API implementation
â”‚   â”‚   â”œâ”€â”€ anthropic-adapter.ts    # Anthropic API implementation
â”‚   â”‚   â”œâ”€â”€ llm-interface.ts        # CMP-to-LLM protocol bridge
â”‚   â”‚   â”œâ”€â”€ prompt-template-manager.ts # Specialized prompts per agent
â”‚   â”‚   â”œâ”€â”€ response-parser.ts      # LLM response to CMP conversion
â”‚   â”‚   â””â”€â”€ index.ts                # Model layer exports
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ agent-types.ts          # 7 specialized agent definitions
â”‚   â”‚   â””â”€â”€ specialized-agents.ts   # Agent morphology extraction
â”‚   â”œâ”€â”€ demo/
â”‚   â”‚   â”œâ”€â”€ phase1-demo.ts          # Phase 1 demonstration
â”‚   â”‚   â”œâ”€â”€ phase2-demo.ts          # Phase 2 demonstration  
â”‚   â”‚   â”œâ”€â”€ phase3-demo.ts          # Phase 3 demonstration
â”‚   â”‚   â”œâ”€â”€ phase4-demo.ts          # NEW: Phase 4 orchestration demo
â”‚   â”‚   â”œâ”€â”€ mcp-integration-demo.ts # NEW: MCP manufacturing integration
â”‚   â”‚   â”œâ”€â”€ gemini-adapter-demo.ts  # NEW: Google Gemini adapter demo
â”‚   â”‚   â”œâ”€â”€ lmstudio-adapter-demo.ts # NEW: LM Studio adapter demo
â”‚   â”‚   â”œâ”€â”€ mock-adapter-demo.ts    # NEW: Mock adapter demo
â”‚   â”‚   â””â”€â”€ cmp-demo.ts             # Original CMP demonstration
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config-loader.ts        # Configuration management
â”‚   â””â”€â”€ index.ts                    # Main entry point
â”œâ”€â”€ config.anthropic_openai.example.json      # OpenAI + Anthropic config
â”œâ”€â”€ config.anthropic_openai_google.example.json # + Google Gemini config
â”œâ”€â”€ config.lmstudio.example.json              # LM Studio config
â”œâ”€â”€ config.mock.example.json                  # Mock testing config
â”œâ”€â”€ config.openai.example.json                # OpenAI only config
â”œâ”€â”€ debug-mcp.sh                              # MCP debug script (Unix)
â”œâ”€â”€ debug-mcp.bat                             # MCP debug script (Windows)
â””â”€â”€ CURRENT-TASK.md                           # Development task tracking
```

## ğŸ§ª What the System Demonstrates

**Phase 1 - Semantic Space Operations:**
```
ğŸ”§ Technical: [45, 67, 23] confidence=0.8
ğŸ¨ Creative: [12, 89, 56] confidence=0.7  
ğŸ¤ Social: [78, 34, 91] confidence=0.9

ğŸ“ Semantic distances:
   ğŸ”§â†’ğŸ¨ Technical to Creative: 76.42
   ğŸ”§â†’ğŸ¤ Technical to Social: 78.13
   ğŸ¨â†’ğŸ¤ Creative to Social: 67.89
```

**Phase 2 - Real LLM Integration:**
```
ğŸ¤– OpenAI GPT-4o: Successfully connected
ğŸ¤– Anthropic Claude: Successfully connected
ğŸ“ CMPâ†’LLM Protocol: Message translation working
ğŸ“‹ Response Parsing: LLM output â†’ CMP evidence format
ğŸ¯ Specialized Prompts: Templates optimized per agent type
```

**Phase 3 - Agent Specialization:**
```
ğŸ§  7 Specialized Agents Working in Parallel:
   ğŸ’­ Reasoning Specialist    â†’ Logical analysis, step-by-step deduction
   ğŸ¨ Creative Specialist     â†’ Innovative solutions, artistic perspectives  
   ğŸ“š Factual Specialist      â†’ Research, citations, verification
   ğŸ’» Code Specialist         â†’ Technical implementation, architecture
   ğŸ¤ Social Specialist       â†’ Human factors, communication, UX
   ğŸ” Critical Specialist     â†’ Risk analysis, edge cases, problems
   ğŸ¯ Coordinator Specialist  â†’ Integration, synthesis, orchestration

ğŸ“Š Distinct Analysis Approaches:
   Quality Scores: 0.529-0.658 (realistic discrimination)
   Confidence Range: 0.400-0.900 (appropriate uncertainty)
   Domain Transformations: 14 cross-domain matrices (0.800 avg reliability)
```

**Phase 4 - Orchestration Engine:**
```
ğŸ¼ Multi-Agent Coordination:
   ğŸ¤ Consensus Building: Thresholds 0.5-0.9, adaptive convergence
   ğŸ” Evidence Aggregation: Cross-agent evidence synthesis
   ğŸ”¬ Formal Verification: Safety, Liveness, Consistency, Completeness
   ğŸ“‹ Coordinated Answers: Integrated multi-perspective solutions

ğŸ“Š Orchestration Metrics:
   Participating agents: 5/7
   Processing time: 2,847ms
   Consensus confidence: 0.742 (High)
   Reasoning diversity: 0.834
   Verification: 4/4 checks passed âœ…
```

**MCP Manufacturing Integration:**
```
ğŸ­ MTConnect Data Analysis:
   ğŸ“Š Analyzing data from 2 devices...
   ğŸ“ˆ Processing 12 observations...
   ğŸ¯ Data quality: 95.0% reliable

ğŸ”— Multi-Agent Manufacturing Analysis:
   ğŸ“Š Factual Specialist: Device performance metrics analysis
   ğŸ§  Reasoning Specialist: Systematic equipment evaluation  
   âš ï¸ Critical Specialist: Risk assessment and maintenance alerts
   ğŸ¯ Meta Coordinator: Manufacturing optimization recommendations

ğŸ“ˆ Analysis Quality:
   â€¢ Overall Confidence: 0.918 (High)
   â€¢ Expert Consensus: âœ… Achieved
   â€¢ Data Integration: âœ… Successful
   â€¢ Agent Alignment: 4/4 specialists agreed
```

**Agent Communication:**
```
ğŸ“¤ Created message:
   ğŸ‘¤ Sender: reasoning_specialist
   ğŸ“ Type: REASONING_ANALYSIS
   ğŸ§  Reasoning steps: 15
   ğŸ“Š Quality: 0.658 (highest performer)
   ğŸ¯ Specialization: logical, methodical, evidence-based
```

**Evidence Aggregation:**
```
ğŸ“Š Multi-agent evidence aggregation:
   ğŸ§  Reasoning agent: 15 steps, quality 0.658
   ğŸ“š Factual agent: 12 steps, quality 0.611  
   ğŸ’» Code agent: 18 steps, quality 0.592
   ğŸ”„ Cross-agent compatibility: 0.847
   âœ… Consensus achieved with formal verification
```

## ğŸ­ The Vision

This is building toward a system where:

```javascript
const result = await orchestrator.orchestrateLLMs(
  "Design a fault-tolerant microservices architecture",
  { constraints: ['security', 'scalability', 'cost'] }
);

// Result includes:
// - Parallel analysis from 7 specialized LLMs
// - Formally verified consensus with confidence scores  
// - Mathematical guarantees about reasoning quality
// - Audit trail of all reasoning steps
// - External data integration (manufacturing, IoT, etc.)
```

## âœ… Completed Phases

**Phase 1: Core CMP Infrastructure**
- âœ… Semantic pose operations in concept space
- âœ… Agent message creation and processing  
- âœ… Evidence aggregation with confidence tracking
- âœ… Cross-agent compatibility checking

**Phase 2: Model Interface Layer**
- âœ… Real OpenAI/Anthropic API integration
- âœ… CMP-to-LLM protocol translation
- âœ… Specialized prompt templates per agent
- âœ… Response parsing and evidence extraction

**Phase 3: Agent Specialization** 
- âœ… 7 distinct agent personalities with unique approaches
- âœ… Knowledge domain transformations between semantic spaces
- âœ… Agent-specific reasoning patterns and morphology extraction
- âœ… Cross-domain compatibility assessment with confidence adjustments

**Phase 4: Orchestration Engine**
- âœ… Parallel agent coordination with load balancing
- âœ… Consensus building algorithms with formal verification
- âœ… Real-time evidence aggregation and conflict resolution
- âœ… External data integration via MCP (MTConnect manufacturing data)
- âœ… Enhanced orchestration requests with external context support

## ğŸ”® Upcoming Phases

**Phase 5: Real-World Applications**
- Code review orchestration across multiple repositories
- Research paper analysis with citation verification
- Strategic decision making with risk assessment
- Enterprise integration and scaling

**Phase 6: Advanced Integration**
- Multi-modal data sources (IoT sensors, databases, APIs)
- Real-time streaming data analysis
- Adaptive agent specialization based on domain
- Cross-organizational collaboration protocols

## ğŸ”¬ Technical Innovation

**Formal Verification for AI:**
- **Safety**: All confidence values âˆˆ [0,1] âœ“
- **Liveness**: System progresses toward consensus âœ“  
- **Consistency**: Reasoning coherent across domains âœ“
- **Completeness**: Sufficient evidence â†’ convergence âœ“

**External Data Integration:**
- **MCP Protocol**: Model Context Protocol for live data feeds
- **Manufacturing Integration**: MTConnect device data analysis
- **Quality Assurance**: Data reliability and freshness metrics
- **Context Preservation**: External data maintains provenance through agent processing

**This isn't just "better prompting" - it's mathematically verified collective intelligence with real-world data integration.**

## ğŸ“Š Expected Output

When you run the different demonstrations:

### Core Orchestration Demo (`npm run dev`)

**Phase 1 Foundation:**
1. **Configuration loading** (requires config.json with API keys)
2. **Agent initialization** (7 specialized agents)
3. **Semantic pose demonstrations** (distance calculations, transforms)

**Phase 2 Model Integration:**
4. **API connectivity** (OpenAI and Anthropic connections)
5. **Protocol translation** (CMP messages â†” LLM prompts)
6. **Response parsing** (LLM output â†’ CMP evidence format)

**Phase 3 Agent Specialization:**
7. **Specialized agent demonstrations** (7 distinct analysis approaches)
8. **Agent-specific reasoning** (logical, creative, factual, technical, social, critical, coordination)
9. **Quality score differentiation** (0.529-0.658 range showing realistic performance differences)
10. **Knowledge domain transformations** (cross-domain semantic mapping)

**Phase 4 Orchestration Engine:**
11. **Multi-agent coordination** (parallel execution and load balancing)
12. **Evidence aggregation** (cross-agent evidence synthesis)
13. **Consensus building** (adaptive thresholds and convergence)
14. **Formal verification** (4-point verification checks)
15. **Coordinated final answers** (integrated multi-perspective solutions)

### MCP Integration Demo (`npm run demo:mcp-integration`)

**Manufacturing Data Integration:**
1. **MCP Server Connection** (MTConnect device discovery)
2. **Live Device Data** (current states and observations)
3. **Multi-Agent Manufacturing Analysis** (specialized perspectives on equipment)
4. **Data Quality Assessment** (reliability, freshness, completeness metrics)
5. **Device-Specific Insights** (targeted equipment recommendations)
6. **Integrated Manufacturing Analysis** (coordinated optimization strategies)

**Success Indicators:**
- âœ… All 7 agents show distinct specialized behaviors
- âœ… Quality scores differentiate agent performance realistically  
- âœ… Confidence values show appropriate uncertainty (0.400-0.900)
- âœ… Cross-domain transformations achieve 0.800+ reliability
- âœ… Real LLM API calls succeed (requires valid API keys)
- âœ… Consensus building achieves convergence with formal verification
- âœ… External data integration maintains quality and provenance
- âœ… Manufacturing analysis provides actionable insights

## ğŸ¤ Contributing

This is currently in active development. Each phase requires explicit approval before proceeding to maintain quality and alignment.

## ğŸ“ License

This is experimental research code exploring the intersection of swarm robotics and language model coordination.

---

**Ready to test the orchestration engine? Run `npm run dev` for Phase 4 demos or `npm run demo:mcp-integration` for manufacturing data analysis! âœ¨**
