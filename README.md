# LLM Orchestration via Cortical Messaging Protocol

A formally verified multi-LLM coordination system that treats language models as distributed agents with mathematical guarantees.

## ğŸ§  What This Is

This system implements **Cortical Messaging Protocol (CMP)** adapted for LLM coordination. Instead of coordinating robots in physical space, we coordinate language models in "semantic space" with:

- **Semantic Poses**: Position in concept space + confidence orientation
- **Evidence Aggregation**: Bayesian confidence combination across agents
- **Formal Verification**: Mathematical guarantees (Safety, Liveness, Consistency, Completeness)
- **Specialized Agents**: 7 expert LLMs working in parallel

## ğŸ¯ Current Status: Phase 3 Complete âœ…

**Core CMP Infrastructure (Phase 1):**
- âœ… Semantic pose operations in concept space
- âœ… Agent message creation and processing  
- âœ… Evidence aggregation with confidence tracking
- âœ… Cross-agent compatibility checking
- âœ… Configurable model management

**Model Interface Layer (Phase 2):**
- âœ… Real OpenAI/Anthropic API integration
- âœ… CMP-to-LLM protocol translation
- âœ… Specialized prompt templates per agent type
- âœ… Response parsing from LLM to CMP format
- âœ… Model adapter factory system

**Agent Specialization System (Phase 3):**
- âœ… 7 distinct specialized agent types (Reasoning, Creative, Factual, Code, Social, Critic, Coordinator)
- âœ… Agent-specific reasoning morphology extraction
- âœ… Knowledge domain transformation system (14 transformation matrices)
- âœ… Cross-domain compatibility checking and confidence adjustments
- âœ… Specialized analysis approaches per agent expertise

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
npm install
```

### 2. Configure API Keys (Required for Phase 2+ demos)
```bash
cp config.example.json config.json
# Edit config.json with your OpenAI and Anthropic API keys
```

### 3. Run Current Demo (Phase 3)
```bash
npm run dev
```

**Note**: Phase 1 demo runs without API keys, but Phase 2+ require real API access for LLM integration.

## ğŸ“ Project Structure

```
llm-cmp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ types/index.ts              # Core type definitions
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ semantic-pose.ts        # Semantic space operations
â”‚   â”‚   â”œâ”€â”€ llm-agent.ts            # Agent base class with specialization
â”‚   â”‚   â”œâ”€â”€ knowledge-domains.ts    # Cross-domain transformations
â”‚   â”‚   â”œâ”€â”€ cmp-demo.ts             # Phase 1 demonstration
â”‚   â”‚   â”œâ”€â”€ phase2-demo.ts          # Phase 2 demonstration  
â”‚   â”‚   â””â”€â”€ phase3-demo.ts          # Phase 3 demonstration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model-adapter.ts        # Abstract base for API adapters
â”‚   â”‚   â”œâ”€â”€ openai-adapter.ts       # OpenAI API implementation
â”‚   â”‚   â”œâ”€â”€ anthropic-adapter.ts    # Anthropic API implementation
â”‚   â”‚   â”œâ”€â”€ llm-interface.ts        # CMP-to-LLM protocol bridge
â”‚   â”‚   â”œâ”€â”€ prompt-template-manager.ts # Specialized prompts per agent
â”‚   â”‚   â”œâ”€â”€ response-parser.ts      # LLM response to CMP conversion
â”‚   â”‚   â””â”€â”€ index.ts                # Model layer exports
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ agent-types.ts          # 7 specialized agent definitions
â”‚   â”‚   â””â”€â”€ specialized-agents.ts   # Agent morphology extraction
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config-loader.ts        # Configuration management
â”‚   â””â”€â”€ index.ts                    # Main entry point
â”œâ”€â”€ config.example.json             # Configuration template
â””â”€â”€ CURRENT-TASK.md                 # Development task tracking
```

## ğŸ§ª What the System Demonstrates

**Phase 1 - Semantic Space Operations:**
```
ğŸ”§ Technical: [45, 67, 23] confidence=0.8
ğŸ¨ Creative: [12, 89, 56] confidence=0.7  
ğŸ¤ Social: [78, 34, 91] confidence=0.9

ğŸ“ Semantic distances:
   ğŸ”§â†’ğŸ¨ Technical to Creative: 76.42
   ğŸ”§â†’ğŸ¤ Technical to Social: 78.13
   ğŸ¨â†’ğŸ¤ Creative to Social: 67.89
```

**Phase 2 - Real LLM Integration:**
```
ğŸ¤– OpenAI GPT-4o: Successfully connected
ğŸ¤– Anthropic Claude: Successfully connected
ğŸ“ CMPâ†’LLM Protocol: Message translation working
ğŸ“‹ Response Parsing: LLM output â†’ CMP evidence format
ğŸ¯ Specialized Prompts: Templates optimized per agent type
```

**Phase 3 - Agent Specialization:**
```
ğŸ§  7 Specialized Agents Working in Parallel:
   ğŸ’­ Reasoning Specialist    â†’ Logical analysis, step-by-step deduction
   ğŸ¨ Creative Specialist     â†’ Innovative solutions, artistic perspectives  
   ğŸ“š Factual Specialist      â†’ Research, citations, verification
   ğŸ’» Code Specialist         â†’ Technical implementation, architecture
   ğŸ¤ Social Specialist       â†’ Human factors, communication, UX
   ğŸ” Critical Specialist     â†’ Risk analysis, edge cases, problems
   ğŸ¯ Coordinator Specialist  â†’ Integration, synthesis, orchestration

ğŸ“Š Distinct Analysis Approaches:
   Quality Scores: 0.529-0.658 (realistic discrimination)
   Confidence Range: 0.400-0.900 (appropriate uncertainty)
   Domain Transformations: 14 cross-domain matrices (0.800 avg reliability)
```

**Agent Communication:**
```
ğŸ“¤ Created message:
   ğŸ‘¤ Sender: reasoning_specialist
   ğŸ“ Type: REASONING_ANALYSIS
   ğŸ§  Reasoning steps: 15
   ğŸ“Š Quality: 0.658 (highest performer)
   ğŸ¯ Specialization: logical, methodical, evidence-based
```

**Evidence Aggregation:**
```
ğŸ“Š Multi-agent evidence aggregation:
   ğŸ§  Reasoning agent: 15 steps, quality 0.658
   ğŸ“š Factual agent: 12 steps, quality 0.611  
   ğŸ’» Code agent: 18 steps, quality 0.592
   ğŸ”„ Cross-agent compatibility: 0.847
   âœ… Consensus achieved with formal verification
```

## ğŸ­ The Vision

This is building toward a system where:

```javascript
const result = await orchestrator.orchestrateLLMs(
  "Design a fault-tolerant microservices architecture",
  { constraints: ['security', 'scalability', 'cost'] }
);

// Result includes:
// - Parallel analysis from 7 specialized LLMs
// - Formally verified consensus with confidence scores  
// - Mathematical guarantees about reasoning quality
// - Audit trail of all reasoning steps
```

## âœ… Completed Phases

**Phase 1: Core CMP Infrastructure**
- âœ… Semantic pose operations in concept space
- âœ… Agent message creation and processing  
- âœ… Evidence aggregation with confidence tracking
- âœ… Cross-agent compatibility checking

**Phase 2: Model Interface Layer**
- âœ… Real OpenAI/Anthropic API integration
- âœ… CMP-to-LLM protocol translation
- âœ… Specialized prompt templates per agent
- âœ… Response parsing and evidence extraction

**Phase 3: Agent Specialization** 
- âœ… 7 distinct agent personalities with unique approaches
- âœ… Knowledge domain transformations between semantic spaces
- âœ… Agent-specific reasoning patterns and morphology extraction
- âœ… Cross-domain compatibility assessment with confidence adjustments

## ğŸ”® Upcoming Phases

**Phase 4: Orchestration Engine**
- Parallel agent coordination with load balancing
- Consensus building algorithms with formal verification
- Real-time evidence aggregation and conflict resolution
- Performance optimization and caching

**Phase 5: Real-World Applications**
- Code review orchestration across multiple repositories
- Research paper analysis with citation verification
- Strategic decision making with risk assessment
- Enterprise integration and scaling

## ğŸ”¬ Technical Innovation

**Formal Verification for AI:**
- **Safety**: All confidence values âˆˆ [0,1] âœ“
- **Liveness**: System progresses toward consensus âœ“  
- **Consistency**: Reasoning coherent across domains âœ“
- **Completeness**: Sufficient evidence â†’ convergence âœ“

**This isn't just "better prompting" - it's mathematically verified collective intelligence.**

## ğŸ“Š Expected Output

When you run `npm run dev`, you should see:

**Phase 1 Foundation:**
1. **Configuration loading** (requires config.json with API keys)
2. **Agent initialization** (7 specialized agents)
3. **Semantic pose demonstrations** (distance calculations, transforms)

**Phase 2 Model Integration:**
4. **API connectivity** (OpenAI and Anthropic connections)
5. **Protocol translation** (CMP messages â†” LLM prompts)
6. **Response parsing** (LLM output â†’ CMP evidence format)

**Phase 3 Agent Specialization:**
7. **Specialized agent demonstrations** (7 distinct analysis approaches)
8. **Agent-specific reasoning** (logical, creative, factual, technical, social, critical, coordination)
9. **Quality score differentiation** (0.529-0.658 range showing realistic performance differences)
10. **Knowledge domain transformations** (cross-domain semantic mapping)
11. **Evidence aggregation** (multi-agent consensus with formal verification)

**Success Indicators:**
- âœ… All 7 agents show distinct specialized behaviors
- âœ… Quality scores differentiate agent performance realistically  
- âœ… Confidence values show appropriate uncertainty (0.400-0.900)
- âœ… Cross-domain transformations achieve 0.800+ reliability
- âœ… Real LLM API calls succeed (requires valid API keys)

## ğŸ¤ Contributing

This is currently in active development. Each phase requires explicit approval before proceeding to maintain quality and alignment.

## ğŸ“ License

This is experimental research code exploring the intersection of swarm robotics and language model coordination.

---

**Ready to test Phase 1? Run `npm run dev` and let's see the magic! âœ¨**
